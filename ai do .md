Tuy·ªát v·ªùi! ƒê√¢y l√† m·ªôt m√¥ t·∫£ d·ª± √°n r·∫•t chi ti·∫øt v√† tham v·ªçng. ƒê·ªÉ tri·ªÉn khai to√†n b·ªô c√°c t√≠nh nƒÉng n√†y trong m·ªôt notebook Colab duy nh·∫•t s·∫Ω r·∫•t ph·ª©c t·∫°p v√† c√≥ th·ªÉ v∆∞·ª£t qu√° gi·ªõi h·∫°n c·ªßa m·ªôt m√¥i tr∆∞·ªùng t∆∞∆°ng t√°c. Tuy nhi√™n, t√¥i s·∫Ω cung c·∫•p cho b·∫°n m·ªôt b·ªô khung m√£ Python cho Colab, t·∫≠p trung v√†o c√°c ch·ª©c nƒÉng c·ªët l√µi b·∫°n ƒë√£ m√¥ t·∫£, ƒë·∫∑c bi·ªát l√† quy tr√¨nh OCR ƒëa t·∫ßng v√† t√≠ch h·ª£p AI c∆° b·∫£n.

**L∆∞u √Ω quan tr·ªçng tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu:**

1.  **API Keys:** B·∫°n s·∫Ω c·∫ßn API key cho Google Gemini (v√† t√πy ch·ªçn cho OpenAI/Claude n·∫øu mu·ªën t√≠ch h·ª£p).
2.  **Th∆∞ vi·ªán:** M·ªôt s·ªë th∆∞ vi·ªán OCR to√°n h·ªçc c√≥ th·ªÉ y√™u c·∫ßu c√†i ƒë·∫∑t ph·ª©c t·∫°p ho·∫∑c c√≥ model l·ªõn. T√¥i s·∫Ω c·ªë g·∫Øng s·ª≠ d·ª•ng c√°c th∆∞ vi·ªán d·ªÖ c√†i ƒë·∫∑t tr√™n Colab.
3.  **Th·ªùi gian x·ª≠ l√Ω:** X·ª≠ l√Ω 50 ·∫£nh v·ªõi nhi·ªÅu t·∫ßng OCR v√† AI c√≥ th·ªÉ t·ªën th·ªùi gian ƒë√°ng k·ªÉ, ƒë·∫∑c bi·ªát n·∫øu kh√¥ng c√≥ GPU.
4.  **ƒê·ªô ch√≠nh x√°c:** ƒê·ªô ch√≠nh x√°c th·ª±c t·∫ø ph·ª• thu·ªôc r·∫•t nhi·ªÅu v√†o ch·∫•t l∆∞·ª£ng ·∫£nh ƒë·∫ßu v√†o v√† s·ª± ph·ª©c t·∫°p c·ªßa c√¥ng th·ª©c.
5.  **T√≠nh nƒÉng "2025":** M·ªôt s·ªë t√≠nh nƒÉng ƒë∆∞·ª£c m√¥ t·∫£ l√† "2025 updated" ho·∫∑c "m·ªõi 2025" c√≥ th·ªÉ l√† gi·∫£ ƒë·ªãnh v·ªÅ c√¥ng ngh·ªá t∆∞∆°ng lai. T√¥i s·∫Ω tri·ªÉn khai d·ª±a tr√™n c√°c c√¥ng c·ª• hi·ªán c√≥ t·ªët nh·∫•t. Texify (VikParuchuri) th∆∞·ªùng ƒë∆∞·ª£c bi·∫øt ƒë·∫øn v·ªõi t√™n `pix2tex` ho·∫∑c `LaTeX-OCR`.
6.  **Gi·ªõi h·∫°n Colab:** X·ª≠ l√Ω song song m·∫°nh m·∫Ω v√† auto-scaling ph·ª©c t·∫°p c√≥ th·ªÉ b·ªã h·∫°n ch·∫ø b·ªüi t√†i nguy√™n Colab.
7.  **Pix2Text:** Th∆∞ vi·ªán n√†y kh√° m·∫°nh, nh∆∞ng c√≥ th·ªÉ c·∫ßn m·ªôt s·ªë b∆∞·ªõc c√†i ƒë·∫∑t ph·ª• thu·ªôc.
8.  **TrOCR:** Th∆∞·ªùng d√πng cho ch·ªØ vi·∫øt tay ho·∫∑c vƒÉn b·∫£n in, kh√¥ng chuy√™n cho LaTeX. T√¥i s·∫Ω ƒë∆∞a v√†o nh∆∞ m·ªôt fallback.

ƒê√¢y l√† b·ªô khung m√£, b·∫°n c√≥ th·ªÉ ch·∫°y t·ª´ng kh·ªëi tr√™n Google Colab:

```python
#@title 1. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
# Th·ªùi gian c√†i ƒë·∫∑t c√≥ th·ªÉ m·∫•t v√†i ph√∫t

# OCR Engines
!pip install pix2tex -q # Cho Texify (LaTeX-OCR)
!pip install transformers sentencepiece Pillow -q # Cho TrOCR v√† c√°c t√°c v·ª• ·∫£nh
!pip install opencv-python-headless numpy -q # Cho ti·ªÅn x·ª≠ l√Ω ·∫£nh
!pip install "unstructured[all-docs]" -q # C√≥ th·ªÉ d√πng cho layout detection ho·∫∑c OCR, nh∆∞ng ·ªü ƒë√¢y s·∫Ω t·∫≠p trung v√†o Pix2Text ri√™ng
!pip install cnocr[onnx-opt] -q # Pix2Text ph·ª• thu·ªôc v√†o cnocr cho ph·∫ßn text
!pip install pix2text -q # Cho Pix2Text

# AI Enhancement
!pip install google-generativeai -q # Cho Gemini
!pip install python-Levenshtein -q # ƒê·ªÉ so s√°nh chu·ªói (v√≠ d·ª•: ƒë√°nh gi√° confidence)
!pip install tqdm -q # ƒê·ªÉ theo d√µi ti·∫øn tr√¨nh

# LaTeX
!pip install pylatexenc -q # ƒê·ªÉ ki·ªÉm tra c√∫ ph√°p LaTeX (c∆° b·∫£n)

# Hi·ªÉn th·ªã ·∫£nh trong Colab
from IPython.display import display, Image as IPImage, Markdown
import os
import shutil # ƒê·ªÉ xo√° th∆∞ m·ª•c t·∫°m
print("‚úÖ C√†i ƒë·∫∑t ho√†n t·∫•t!")
```

```python
#@title 2. Import c√°c th∆∞ vi·ªán v√† thi·∫øt l·∫≠p API Key
import os
import glob
import shutil
import time
import json
import csv
from concurrent.futures import ThreadPoolExecutor, as_completed
from uuid import uuid4

import cv2
import numpy as np
from PIL import Image as PILImage
from tqdm.notebook import tqdm # Progress bar cho notebook
from google.colab import files
import getpass

# OCR specific imports
from pix2tex.cli import LatexOCR # Texify / LaTeX-OCR
from pix2text import Pix2Text # Pix2Text
from transformers import TrOCRProcessor, VisionEncoderDecoderModel # TrOCR

# AI Enhancement
import google.generativeai as genai

# LaTeX validation
from pylatexenc.latexwalker import LatexWalkerError
from pylatexenc.latex2text import LatexNodes2Text

# --- C·∫•u h√¨nh API Key ---
# B·∫°n c√≥ th·ªÉ ƒë·∫∑t API key tr·ª±c ti·∫øp v√†o code n·∫øu ch·ªâ d√πng c√° nh√¢n,
# nh∆∞ng d√πng getpass an to√†n h∆°n khi chia s·∫ª notebook.
try:
    from google.colab import userdata
    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
    if not GEMINI_API_KEY:
        print("‚ö†Ô∏è Gemini API Key ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p trong Colab Secrets.")
        print("Vui l√≤ng t·∫°o Secret c√≥ t√™n 'GEMINI_API_KEY' v√† d√°n API Key c·ªßa b·∫°n v√†o ƒë√≥.")
        GEMINI_API_KEY = getpass.getpass('Ho·∫∑c nh·∫≠p Google AI Studio API Key c·ªßa b·∫°n: ')
except ImportError: # Fallback cho m√¥i tr∆∞·ªùng kh√¥ng ph·∫£i Colab ho·∫∑c Colab c≈©
    GEMINI_API_KEY = getpass.getpass('Nh·∫≠p Google AI Studio API Key c·ªßa b·∫°n: ')

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    print("‚úÖ Gemini API Key ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh.")
else:
    print("‚õî Gemini API Key ch∆∞a ƒë∆∞·ª£c cung c·∫•p. Ch·ª©c nƒÉng AI Enhancement s·∫Ω b·ªã v√¥ hi·ªáu h√≥a.")

# --- Kh·ªüi t·∫°o c√°c model OCR (c√≥ th·ªÉ t·ªën th·ªùi gian) ---
# B·∫°n c√≥ th·ªÉ di chuy·ªÉn vi·ªác kh·ªüi t·∫°o n√†y v√†o h√†m x·ª≠ l√Ω ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ n·∫øu c·∫ßn
# nh∆∞ng s·∫Ω l√†m ch·∫≠m m·ªói l·∫ßn g·ªçi.

# T·∫ßng 1: Texify (LaTeX-OCR)
try:
    latex_ocr_model = LatexOCR()
    print("‚úÖ LaTeX-OCR (Texify) model loaded.")
except Exception as e:
    latex_ocr_model = None
    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i LaTeX-OCR model: {e}")

# T·∫ßng 2: Pix2Text
# Pix2Text c√≥ th·ªÉ c·∫ßn t·∫£i model l·∫ßn ƒë·∫ßu ch·∫°y
try:
    p2t_model = Pix2Text() # M·∫∑c ƒë·ªãnh d√πng model cho ti·∫øng Anh v√† c√¥ng th·ª©c
    print("‚úÖ Pix2Text model loaded.")
except Exception as e:
    p2t_model = None
    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i Pix2Text model: {e}")


# T·∫ßng 3: TrOCR (fallback) - N√™n d√πng model 'printed' cho ƒë·ªÅ thi
# S·ª≠ d·ª•ng model nh·ªè h∆°n ƒë·ªÉ ti·∫øt ki·ªám t√†i nguy√™n tr√™n Colab n·∫øu c·∫ßn
# V√≠ d·ª•: 'microsoft/trocr-small-printed'
try:
    trocr_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')
    trocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')
    print("‚úÖ TrOCR model loaded.")
except Exception as e:
    trocr_processor = None
    trocr_model = None
    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i TrOCR model: {e}")

# Th∆∞ m·ª•c l√†m vi·ªác
BASE_DIR = "math_ocr_processor_2025"
INPUT_DIR = os.path.join(BASE_DIR, "input_images")
OUTPUT_DIR = os.path.join(BASE_DIR, "output_latex")
PREVIEW_DIR = os.path.join(BASE_DIR, "output_previews") # Th∆∞ m·ª•c cho ·∫£nh render LaTeX (n·∫øu c√≥)
TEMP_PREPROC_DIR = os.path.join(BASE_DIR, "temp_preprocessed") # Th∆∞ m·ª•c ·∫£nh ƒë√£ ti·ªÅn x·ª≠ l√Ω

# T·∫°o c√°c th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
os.makedirs(INPUT_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(PREVIEW_DIR, exist_ok=True)
os.makedirs(TEMP_PREPROC_DIR, exist_ok=True)

print(f"üóÇÔ∏è C√°c th∆∞ m·ª•c l√†m vi·ªác ƒë√£ ƒë∆∞·ª£c t·∫°o t·∫°i: {BASE_DIR}")
```

```python
#@title 3. C√°c h√†m Ti·ªÅn X·ª≠ L√Ω ·∫¢nh Th√¥ng Minh
def preprocess_image(image_path, output_path, target_size_ocr=None):
    """
    Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng cho OCR.
    target_size_ocr: (width, height) tuple for resizing for specific OCR, or None.
    """
    try:
        img = cv2.imread(image_path)
        if img is None:
            print(f"L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image_path}")
            return None

        # 1. Chuy·ªÉn ƒë·ªïi sang grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # 2. Adaptive thresholding ƒë·ªÉ nh·ªã ph√¢n h√≥a ·∫£nh
        # C√≥ th·ªÉ th·ª≠ c√°c gi√° tr·ªã blockSize v√† C kh√°c nhau
        binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                       cv2.THRESH_BINARY, 11, 2)

        # 3. Kh·ª≠ nhi·ªÖu (v√≠ d·ª•: median blur)
        denoised = cv2.medianBlur(binary, 3) # K√≠ch th∆∞·ªõc kernel c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh

        # 4. TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n (kh√¥ng c·∫ßn thi·∫øt l·∫Øm sau thresholding, nh∆∞ng c√≥ th·ªÉ th·ª≠ tr√™n ·∫£nh g·ªëc)
        # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        # contrasted = clahe.apply(gray) # √°p d·ª•ng tr√™n ·∫£nh x√°m

        # 5. Crop th√¥ng minh: Lo·∫°i b·ªè vi·ªÅn tr·∫Øng (ƒë∆°n gi·∫£n)
        # T√¨m contours, l·∫•y bounding box c·ªßa contour l·ªõn nh·∫•t ho·∫∑c t·∫•t c·∫£ c√°c contours
        # ƒê√¢y l√† m·ªôt phi√™n b·∫£n ƒë∆°n gi·∫£n h√≥a
        contours, _ = cv2.findContours(cv2.bitwise_not(denoised), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            # Gi·∫£ s·ª≠ n·ªôi dung ch√≠nh l√† m·ªôt kh·ªëi l·ªõn
            # Ho·∫∑c c√≥ th·ªÉ k·∫øt h·ª£p bounding box c·ªßa nhi·ªÅu contours
            x_coords = []
            y_coords = []
            for contour in contours:
                x, y, w, h = cv2.boundingRect(contour)
                # L·ªçc c√°c contour qu√° nh·ªè
                if w*h > 100: # Ng∆∞·ª°ng di·ªán t√≠ch, c·∫ßn ƒëi·ªÅu ch·ªânh
                    x_coords.extend([x, x+w])
                    y_coords.extend([y, y+h])

            if x_coords and y_coords:
                min_x, max_x = min(x_coords), max(x_coords)
                min_y, max_y = min(y_coords), max(y_coords)
                # Th√™m m·ªôt ch√∫t padding
                padding = 10
                min_x = max(0, min_x - padding)
                min_y = max(0, min_y - padding)
                max_x = min(img.shape[1], max_x + padding)
                max_y = min(img.shape[0], max_y + padding)

                cropped_img = denoised[min_y:max_y, min_x:max_x]
                if cropped_img.size == 0: # N·∫øu crop l·ªói, d√πng ·∫£nh ƒë√£ kh·ª≠ nhi·ªÖu
                    final_image = denoised
                else:
                    final_image = cropped_img
            else: # Kh√¥ng t√¨m th·∫•y contour ph√π h·ª£p
                final_image = denoised
        else:
            final_image = denoised # N·∫øu kh√¥ng c√≥ contour, d√πng ·∫£nh ƒë√£ kh·ª≠ nhi·ªÖu

        # 6. Resize (t√πy ch·ªçn, m·ªôt s·ªë OCR engine c√≥ y√™u c·∫ßu ri√™ng)
        if target_size_ocr:
            final_image = cv2.resize(final_image, target_size_ocr, interpolation=cv2.INTER_LANCZOS4)

        cv2.imwrite(output_path, final_image)
        return output_path
    except Exception as e:
        print(f"L·ªói ti·ªÅn x·ª≠ l√Ω ·∫£nh {image_path}: {e}")
        # N·∫øu l·ªói, th·ª≠ l∆∞u ·∫£nh g·ªëc v√†o output_path ƒë·ªÉ OCR engine v·∫´n c√≥ th·ªÉ th·ª≠
        try:
            shutil.copy(image_path, output_path)
            return output_path
        except:
            return None


# H√†m ph√°t hi·ªán v√† xoay ·∫£nh (ƒë∆°n gi·∫£n, c√≥ th·ªÉ c·∫ßn c·∫£i thi·ªán)
def deskew_image(image_path, output_path):
    try:
        image = cv2.imread(image_path)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        gray = cv2.bitwise_not(gray) # ƒê·∫£o ng∆∞·ª£c m√†u ƒë·ªÉ text th√†nh tr·∫Øng, n·ªÅn ƒëen
        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]

        coords = np.column_stack(np.where(thresh > 0))
        angle = cv2.minAreaRect(coords)[-1] # G√≥c tr·∫£ v·ªÅ trong kho·∫£ng [-90, 0)

        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle

        (h, w) = image.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated = cv2.warpAffine(image, M, (w, h),
            flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

        # C√≥ th·ªÉ c·∫ßn crop l·∫°i sau khi xoay ƒë·ªÉ b·ªè vi·ªÅn ƒëen
        # (ƒê·ªÉ ƒë∆°n gi·∫£n, t·∫°m th·ªùi b·ªè qua b∆∞·ªõc crop ph·ª©c t·∫°p n√†y)
        cv2.imwrite(output_path, rotated)
        return output_path
    except Exception as e:
        print(f"L·ªói xoay ·∫£nh {image_path}: {e}")
        try:
            shutil.copy(image_path, output_path) # Tr·∫£ v·ªÅ ·∫£nh g·ªëc n·∫øu l·ªói
            return output_path
        except:
            return None

print("‚úÖ C√°c h√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë√£ s·∫µn s√†ng.")
```

```python
#@title 4. C√°c h√†m OCR Engine
def ocr_with_texify(image_path):
    """S·ª≠ d·ª•ng LaTeX-OCR (Texify)"""
    if not latex_ocr_model:
        return None, 0.0
    try:
        pil_img = PILImage.open(image_path)
        # Kh√¥ng c√≥ confidence score tr·ª±c ti·∫øp t·ª´ th∆∞ vi·ªán n√†y m·ªôt c√°ch d·ªÖ d√†ng
        # Ta c√≥ th·ªÉ gi·∫£ ƒë·ªãnh l√† cao n·∫øu c√≥ k·∫øt qu·∫£
        latex_code = latex_ocr_model(pil_img)
        confidence = 0.95 if latex_code and latex_code.strip() else 0.0
        return latex_code, confidence
    except Exception as e:
        print(f"L·ªói Texify OCR: {e}")
        return None, 0.0

def ocr_with_pix2text(image_path):
    """S·ª≠ d·ª•ng Pix2Text"""
    if not p2t_model:
        return None, 0.0
    try:
        # Pix2Text tr·∫£ v·ªÅ list c√°c dict, m·ªói dict l√† 1 ph·∫ßn t·ª≠ (text, formula)
        # Ta c·∫ßn gh√©p c√°c ph·∫ßn t·ª≠ formula l·∫°i
        results = p2t_model.recognize(image_path)
        latex_formulas = [item['text'] for item in results if item['type'] == 'formula']

        if not latex_formulas:
            # N·∫øu kh√¥ng c√≥ formula, th·ª≠ l·∫•y text th∆∞·ªùng v√† coi ƒë√≥ l√† LaTeX (√≠t ch√≠nh x√°c)
            all_text = " ".join([item['text'] for item in results])
            if all_text:
                return all_text, 0.6 # Confidence th·∫•p h∆°n
            return None, 0.0

        # N·ªëi c√°c c√¥ng th·ª©c n·∫øu c√≥ nhi·ªÅu (hi·∫øm khi v·ªõi 1 c√¢u h·ªèi l√† 1 ·∫£nh)
        full_latex = " ".join(latex_formulas)
        # Pix2Text kh√¥ng tr·∫£ confidence tr·ª±c ti·∫øp, d·ª±a v√†o k·∫øt qu·∫£
        confidence = 0.85 if full_latex and full_latex.strip() else 0.0
        return full_latex, confidence
    except Exception as e:
        print(f"L·ªói Pix2Text OCR: {e}")
        return None, 0.0

def ocr_with_trocr(image_path):
    """S·ª≠ d·ª•ng TrOCR (ch·ªß y·∫øu cho text, fallback)"""
    if not trocr_processor or not trocr_model:
        return None, 0.0
    try:
        pil_img = PILImage.open(image_path).convert("RGB")
        pixel_values = trocr_processor(images=pil_img, return_tensors="pt").pixel_values
        generated_ids = trocr_model.generate(pixel_values)
        generated_text = trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        # TrOCR kh√¥ng chuy√™n cho LaTeX, confidence th·∫•p h∆°n
        confidence = 0.50 if generated_text and generated_text.strip() else 0.0
        return generated_text, confidence
    except Exception as e:
        print(f"L·ªói TrOCR: {e}")
        return None, 0.0

OCR_ENGINES = {
    "Texify (LaTeX-OCR)": ocr_with_texify,
    "Pix2Text": ocr_with_pix2text,
    "TrOCR (Fallback)": ocr_with_trocr,
}
OCR_ENGINE_PRIORITY = ["Texify (LaTeX-OCR)", "Pix2Text", "TrOCR (Fallback)"]

print("‚úÖ C√°c h√†m OCR ƒë√£ s·∫µn s√†ng.")
```

```python
#@title 5. H√†m AI Enhancement (Google Gemini)
def enhance_with_gemini(latex_code, question_context=""):
    """
    S·ª≠ d·ª•ng Gemini ƒë·ªÉ s·ª≠a l·ªói c√∫ ph√°p LaTeX v√† chu·∫©n h√≥a.
    question_context: c√≥ th·ªÉ l√† lo·∫°i c√¢u h·ªèi ho·∫∑c th√¥ng tin th√™m.
    """
    if not GEMINI_API_KEY or not genai:
        print("Gemini API kh√¥ng kh·∫£ d·ª•ng. B·ªè qua enhancement.")
        return latex_code, "Gemini API not configured"

    if not latex_code or not latex_code.strip():
        return "", "Input LaTeX is empty"

    model = genai.GenerativeModel('gemini-pro')
    prompt = f"""
    Given the following OCR'd LaTeX string, please correct any syntax errors and ensure it's a valid mathematical expression.
    Return ONLY the corrected LaTeX code. Do not add any explanation or surrounding text.
    If the input is already perfect or very good, return it as is.
    If the input seems to be mostly text and not a math formula, try to format it as plain text within a LaTeX environment if appropriate, or return the original text.

    Context (if any): {question_context}

    Original LaTeX:
    ```latex
    {latex_code}
    ```

    Corrected LaTeX:
    """
    try:
        response = model.generate_content(prompt)
        # Lo·∫°i b·ªè ```latex v√† ``` n·∫øu c√≥
        enhanced_text = response.text.strip()
        if enhanced_text.startswith("```latex"):
            enhanced_text = enhanced_text[len("```latex"):].strip()
        if enhanced_text.endswith("```"):
            enhanced_text = enhanced_text[:-len("```")].strip()
        return enhanced_text, "Successfully enhanced by Gemini"
    except Exception as e:
        print(f"L·ªói Gemini API: {e}")
        return latex_code, f"Gemini API error: {e}"

print("‚úÖ H√†m AI Enhancement ƒë√£ s·∫µn s√†ng.")
```

```python
#@title 6. H√†m Quality Control & Validation
def validate_latex_syntax(latex_code):
    """
    Ki·ªÉm tra c√∫ ph√°p LaTeX c∆° b·∫£n.
    Tr·∫£ v·ªÅ True n·∫øu h·ª£p l·ªá (ho·∫∑c kh√¥ng th·ªÉ ki·ªÉm tra), False n·∫øu c√≥ l·ªói r√µ r√†ng.
    """
    if not latex_code or not latex_code.strip():
        return False, "Empty LaTeX"
    try:
        # Th·ª≠ parse LaTeX, n·∫øu kh√¥ng c√≥ l·ªói nghi√™m tr·ªçng th√¨ coi l√† ·ªïn
        # ƒê√¢y l√† ki·ªÉm tra r·∫•t c∆° b·∫£n
        LatexNodes2Text().latex_to_text(latex_code)
        return True, "Syntax appears valid (basic check)"
    except LatexWalkerError as e:
        # print(f"L·ªói c√∫ ph√°p LaTeX: {e}") # G·ª° comment n·∫øu mu·ªën debug
        return False, f"Syntax error: {e}"
    except Exception as e: # C√°c l·ªói kh√°c kh√¥ng l∆∞·ªùng tr∆∞·ªõc
        # print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi ki·ªÉm tra LaTeX: {e}")
        return True, f"Unknown validation error (assumed valid): {e}" # T·∫°m coi l√† True ƒë·ªÉ kh√¥ng ch·∫∑n qu√° tr√¨nh

print("‚úÖ H√†m Quality Control ƒë√£ s·∫µn s√†ng.")
```

```python
#@title 7. H√†m X·ª≠ L√Ω Ch√≠nh (Single Image) v√† Batch Processing
# C·∫•u h√¨nh
ENABLE_DESKEW = False # ƒê·∫∑t True ƒë·ªÉ th·ª≠ deskew, c√≥ th·ªÉ l√†m ch·∫≠m v√† kh√¥ng lu√¥n hi·ªáu qu·∫£
ENABLE_AI_ENHANCEMENT = True # ƒê·∫∑t True ƒë·ªÉ s·ª≠ d·ª•ng Gemini

def process_single_image(image_path, image_idx, total_images, temp_dir):
    """
    Quy tr√¨nh x·ª≠ l√Ω cho m·ªôt ·∫£nh ƒë∆°n l·∫ª.
    """
    filename = os.path.basename(image_path)
    unique_id = str(uuid4()) # ƒê·ªÉ tr√°nh tr√πng t√™n file t·∫°m
    print(f"Processing [{image_idx+1}/{total_images}]: {filename}")

    result = {
        "original_filename": filename,
        "output_filename_pattern": f"question_{image_idx+1:02d}",
        "processed_image_path": None,
        "raw_latex": None,
        "ocr_engine_used": None,
        "ocr_confidence": 0.0,
        "enhanced_latex": None,
        "ai_enhancement_status": None,
        "latex_syntax_valid": False,
        "validation_message": "",
        "processing_time": 0.0,
        "error": None
    }
    start_time = time.time()

    try:
        # 1. Ti·ªÅn x·ª≠ l√Ω ·∫£nh
        # T·∫°o t√™n file t·∫°m duy nh·∫•t cho ·∫£nh ƒë√£ ti·ªÅn x·ª≠ l√Ω
        preprocessed_image_name = f"preprocessed_{result['output_filename_pattern']}_{unique_id}.png"
        temp_preprocessed_path = os.path.join(temp_dir, preprocessed_image_name)

        if ENABLE_DESKEW:
            deskewed_path_name = f"deskewed_{result['output_filename_pattern']}_{unique_id}.png"
            deskewed_path = os.path.join(temp_dir, deskewed_path_name)
            deskewed_image_path = deskew_image(image_path, deskewed_path)
            if not deskewed_image_path: # N·∫øu deskew l·ªói, d√πng ·∫£nh g·ªëc
                deskewed_image_path = image_path
        else:
            deskewed_image_path = image_path # B·ªè qua deskew

        processed_path = preprocess_image(deskewed_image_path, temp_preprocessed_path)
        if not processed_path:
            raise ValueError("Image preprocessing failed.")
        result["processed_image_path"] = processed_path

        # 2. OCR ƒëa t·∫ßng
        raw_latex_output = None
        selected_engine = None
        highest_confidence = 0.0

        for engine_name in OCR_ENGINE_PRIORITY:
            if engine_name in OCR_ENGINES:
                print(f"  Trying OCR Engine: {engine_name}...")
                ocr_func = OCR_ENGINES[engine_name]
                try:
                    latex, confidence = ocr_func(processed_path)
                    if latex and latex.strip(): # ∆Øu ti√™n engine n√†o c√≥ k·∫øt qu·∫£
                        # N·∫øu c√≥ k·∫øt qu·∫£ v√† confidence cao h∆°n, ho·∫∑c l√† engine ƒë·∫ßu ti√™n c√≥ k·∫øt qu·∫£
                        if latex and (confidence > highest_confidence or not raw_latex_output):
                            raw_latex_output = latex
                            selected_engine = engine_name
                            highest_confidence = confidence
                            print(f"    ‚ú® Got result from {engine_name} (Conf: {confidence:.2f})")
                            # N·∫øu l√† engine ∆∞u ti√™n cao (Texify) v√† c√≥ k·∫øt qu·∫£ t·ªët, c√≥ th·ªÉ d·ª´ng s·ªõm
                            if engine_name == "Texify (LaTeX-OCR)" and confidence > 0.9: # Ng∆∞·ª°ng t·ª± tin
                                break
                except Exception as e:
                    print(f"    ‚ö†Ô∏è Error with {engine_name}: {e}")
            else:
                print(f"  Engine {engine_name} not available or not loaded.")

        result["raw_latex"] = raw_latex_output
        result["ocr_engine_used"] = selected_engine
        result["ocr_confidence"] = highest_confidence

        if not raw_latex_output:
            print(f"  ‚ö†Ô∏è No OCR engine could extract LaTeX for {filename}.")
            result["error"] = "All OCR engines failed or returned empty."
        else:
            # 3. AI Enhancement (T√πy ch·ªçn)
            if ENABLE_AI_ENHANCEMENT and GEMINI_API_KEY:
                print(f"  Enhancing with Gemini...")
                enhanced_l, enhance_status = enhance_with_gemini(raw_latex_output)
                result["enhanced_latex"] = enhanced_l
                result["ai_enhancement_status"] = enhance_status
            else:
                result["enhanced_latex"] = raw_latex_output # D√πng raw n·∫øu AI kh√¥ng b·∫≠t/l·ªói
                result["ai_enhancement_status"] = "Skipped or API not available"

            # 4. Quality Control & Validation
            final_latex_to_validate = result["enhanced_latex"] if result["enhanced_latex"] else result["raw_latex"]
            is_valid, val_msg = validate_latex_syntax(final_latex_to_validate)
            result["latex_syntax_valid"] = is_valid
            result["validation_message"] = val_msg
            if not is_valid:
                 print(f"  ‚ö†Ô∏è LaTeX syntax validation failed for {filename}: {val_msg}")


    except Exception as e:
        print(f"Critical error processing {filename}: {e}")
        result["error"] = str(e)

    result["processing_time"] = time.time() - start_time
    return result

def batch_process_images(image_paths, output_dir, temp_preproc_dir, max_workers=4):
    """
    X·ª≠ l√Ω h√†ng lo·∫°t ·∫£nh s·ª≠ d·ª•ng ThreadPoolExecutor.
    """
    all_results = []
    # Gi·ªõi h·∫°n max_workers ƒë·ªÉ tr√°nh qu√° t·∫£i Colab, ƒë·∫∑c bi·ªát v·ªõi c√°c model n·∫∑ng
    # max_workers = min(max_workers, os.cpu_count() or 1)
    # V·ªõi Colab, 2-4 workers th∆∞·ªùng l√† h·ª£p l√Ω, t√πy thu·ªôc v√†o model c√≥ d√πng GPU kh√¥ng.

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # T·∫°o future cho m·ªói ·∫£nh
        futures = {
            executor.submit(process_single_image, img_path, idx, len(image_paths), temp_preproc_dir): img_path
            for idx, img_path in enumerate(image_paths)
        }

        # Thu th·∫≠p k·∫øt qu·∫£ khi ho√†n th√†nh, c√≥ progress bar
        for future in tqdm(as_completed(futures), total=len(image_paths), desc="Batch Processing Images"):
            img_path = futures[future]
            try:
                single_result = future.result()
                all_results.append(single_result)

                # L∆∞u file .tex c√° nh√¢n
                if single_result.get("raw_latex"): # Ch·ªâ l∆∞u n·∫øu c√≥ k·∫øt qu·∫£ OCR
                    final_latex = single_result.get("enhanced_latex") or single_result.get("raw_latex")
                    output_tex_filename = f"{single_result['output_filename_pattern']}.tex"
                    output_tex_path = os.path.join(output_dir, output_tex_filename)
                    with open(output_tex_path, "w", encoding="utf-8") as f:
                        f.write(final_latex if final_latex else "% No LaTeX extracted")
                    # print(f"  Saved: {output_tex_path}")

            except Exception as e:
                print(f"Error processing future for {img_path}: {e}")
                all_results.append({
                    "original_filename": os.path.basename(img_path),
                    "error": str(e),
                    "processing_time": 0.0 # Ho·∫∑c ƒëo th·ªùi gian t·ªõi l√∫c l·ªói
                })
    # S·∫Øp x·∫øp l·∫°i k·∫øt qu·∫£ theo th·ª© t·ª± ban ƒë·∫ßu (n·∫øu c·∫ßn, d·ª±a tr√™n output_filename_pattern)
    all_results.sort(key=lambda r: r.get("output_filename_pattern", ""))
    return all_results

print("‚úÖ H√†m x·ª≠ l√Ω ch√≠nh v√† batch ƒë√£ s·∫µn s√†ng.")
```

```python
#@title 8. Nh·∫≠p Li·ªáu v√† Ch·∫°y X·ª≠ L√Ω

# D·ªçn d·∫πp th∆∞ m·ª•c input v√† output c≈© (n·∫øu c·∫ßn)
# Th·∫≠n tr·ªçng khi d√πng c√°c l·ªánh n√†y!
# if os.path.exists(INPUT_DIR): shutil.rmtree(INPUT_DIR)
# if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)
# if os.path.exists(PREVIEW_DIR): shutil.rmtree(PREVIEW_DIR)
# if os.path.exists(TEMP_PREPROC_DIR): shutil.rmtree(TEMP_PREPROC_DIR)

# os.makedirs(INPUT_DIR, exist_ok=True)
# os.makedirs(OUTPUT_DIR, exist_ok=True)
# os.makedirs(PREVIEW_DIR, exist_ok=True)
# os.makedirs(TEMP_PREPROC_DIR, exist_ok=True) # T·∫°o l·∫°i th∆∞ m·ª•c t·∫°m

print(f"Vui l√≤ng upload c√°c file ·∫£nh c√¢u h·ªèi (JPG, PNG, BMP, TIFF, WebP) v√†o th∆∞ m·ª•c '{INPUT_DIR}'.")
print(f"B·∫°n c√≥ th·ªÉ d√πng panel 'Files' b√™n tr√°i c·ªßa Colab ƒë·ªÉ k√©o th·∫£ ho·∫∑c upload.")
print(f"Sau khi upload xong, ch·∫°y cell n√†y m·ªôt l·∫ßn n·ªØa (ho·∫∑c cell ti·∫øp theo).")

# C√°ch 1: Upload tr·ª±c ti·∫øp qua Colab UI (ch·∫°y cell n√†y ƒë·ªÉ hi·ªán n√∫t Upload)
# L∆∞u √Ω: c√°ch n√†y kh√¥ng t·ª± ƒë·ªông qu√©t th∆∞ m·ª•c, b·∫°n ph·∫£i upload v√†o ƒë√∫ng INPUT_DIR
# Ho·∫∑c d√πng c√°ch upload n√†y r·ªìi copy file v√†o INPUT_DIR
# uploaded_files = files.upload()
# for filename, content in uploaded_files.items():
#     with open(os.path.join(INPUT_DIR, filename), 'wb') as f:
#         f.write(content)
#     print(f'ƒê√£ l∆∞u file {filename} v√†o {INPUT_DIR}')

# V√≠ d·ª•: Th√™m m·ªôt v√†i ·∫£nh m·∫´u ƒë·ªÉ test n·∫øu kh√¥ng c√≥ ·∫£nh th·∫≠t
# B·∫°n c√≥ th·ªÉ comment ƒëo·∫°n n√†y n·∫øu ƒë√£ upload ·∫£nh th·∫≠t.
# T·∫°o ·∫£nh m·∫´u (n·∫øu kh√¥ng c√≥)
def create_dummy_image(filepath, text="Sample Math: $x^2 + y^2 = z^2$"):
    try:
        from PIL import Image, ImageDraw, ImageFont
        img = Image.new('RGB', (400, 100), color = (255, 255, 255))
        d = ImageDraw.Draw(img)
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except IOError:
            font = ImageFont.load_default()
        d.text((10,30), text, fill=(0,0,0), font=font)
        img.save(filepath)
        return True
    except ImportError:
        print("Pillow.ImageFont kh√¥ng t√¨m th·∫•y, kh√¥ng t·∫°o ƒë∆∞·ª£c ·∫£nh m·∫´u.")
        return False
    except Exception as e:
        print(f"L·ªói t·∫°o ·∫£nh m·∫´u: {e}")
        return False

# Ki·ªÉm tra n·∫øu INPUT_DIR r·ªóng th√¨ t·∫°o ·∫£nh m·∫´u
if not os.listdir(INPUT_DIR):
    print("Th∆∞ m·ª•c INPUT_DIR r·ªóng. T·∫°o ·∫£nh m·∫´u...")
    create_dummy_image(os.path.join(INPUT_DIR, "dummy_question_01.png"), "$\\sum_{i=1}^n i = \\frac{n(n+1)}{2}$")
    create_dummy_image(os.path.join(INPUT_DIR, "dummy_question_02.jpg"), "$E=mc^2$ (Einstein)")
    create_dummy_image(os.path.join(INPUT_DIR, "dummy_question_03.png"), "Text with math $\\alpha + \\beta$")
else:
    print(f"T√¨m th·∫•y {len(os.listdir(INPUT_DIR))} file(s) trong {INPUT_DIR}.")


# --- B·∫Øt ƒë·∫ßu x·ª≠ l√Ω ---
# L·∫•y danh s√°ch file ·∫£nh t·ª´ INPUT_DIR
image_extensions = ("*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tiff", "*.webp")
input_image_paths = []
for ext in image_extensions:
    input_image_paths.extend(glob.glob(os.path.join(INPUT_DIR, ext)))

if not input_image_paths:
    print("‚õî Kh√¥ng t√¨m th·∫•y file ·∫£nh n√†o trong th∆∞ m·ª•c input. Vui l√≤ng upload ·∫£nh v√† ch·∫°y l·∫°i.")
else:
    print(f"T√¨m th·∫•y {len(input_image_paths)} ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.")
    # Hi·ªÉn th·ªã m·ªôt v√†i ·∫£nh ƒë·∫ßu v√†o (t√πy ch·ªçn)
    # for i, img_path in enumerate(input_image_paths[:3]):
    #     print(f"Input image {i+1}: {os.path.basename(img_path)}")
    #     display(IPImage(filename=img_path, width=300))

    # Thi·∫øt l·∫≠p s·ªë worker cho x·ª≠ l√Ω song song
    # Tr√™n Colab free tier, 2-4 l√† h·ª£p l√Ω. N·∫øu c√≥ GPU v√† model d√πng GPU, c√≥ th·ªÉ kh√°c.
    num_workers = 2 # ƒêi·ªÅu ch·ªânh n·∫øu c·∫ßn

    print(f"\nüöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω h√†ng lo·∫°t v·ªõi {num_workers} worker(s)...")
    processing_results = batch_process_images(input_image_paths, OUTPUT_DIR, TEMP_PREPROC_DIR, max_workers=num_workers)
    print("\n‚úÖ X·ª≠ l√Ω h√†ng lo·∫°t ho√†n t·∫•t!")

    # D·ªçn d·∫πp th∆∞ m·ª•c t·∫°m ch·ª©a ·∫£nh ƒë√£ ti·ªÅn x·ª≠ l√Ω
    if os.path.exists(TEMP_PREPROC_DIR):
        try:
            shutil.rmtree(TEMP_PREPROC_DIR)
            print(f"üóëÔ∏è ƒê√£ x√≥a th∆∞ m·ª•c t·∫°m: {TEMP_PREPROC_DIR}")
            os.makedirs(TEMP_PREPROC_DIR, exist_ok=True) # T·∫°o l·∫°i cho l·∫ßn ch·∫°y sau
        except Exception as e:
            print(f"L·ªói khi x√≥a th∆∞ m·ª•c t·∫°m: {e}")
```

```python
#@title 9. Export & Output Options + B√°o C√°o
def generate_report(results, output_dir):
    if not results:
        print("Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªÉ t·∫°o b√°o c√°o.")
        return

    # --- 1. Compiled LaTeX Document ---
    compiled_tex_path = os.path.join(output_dir, "compiled_document.tex")
    # T·∫°o m·ªôt file .tex ho√†n ch·ªânh ch·ª©a t·∫•t c·∫£ c√°c c√¢u h·ªèi
    # B·∫°n c·∫ßn m·ªôt tr√¨nh bi√™n d·ªãch LaTeX (nh∆∞ MiKTeX, TeX Live) ƒë·ªÉ bi√™n d·ªãch file n√†y th√†nh PDF.
    # Colab kh√¥ng c√≥ s·∫µn tr√¨nh bi√™n d·ªãch LaTeX ƒë·∫ßy ƒë·ªß.
    # Ch√∫ng ta ch·ªâ t·∫°o file .tex ngu·ªìn.
    with open(compiled_tex_path, "w", encoding="utf-8") as f:
        f.write("\\documentclass{article}\n")
        f.write("\\usepackage{amsmath, amssymb,amsfonts}\n")
        f.write("\\usepackage[utf8]{inputenc}\n")
        f.write("\\usepackage{geometry}\n")
        f.write("\\geometry{a4paper, margin=1in}\n")
        f.write("\\title{T·ªïng h·ª£p C√¢u h·ªèi To√°n OCR}\n")
        f.write("\\author{Free Math OCR Batch Processor 2025}\n")
        f.write("\\date{\\today}\n")
        f.write("\\begin{document}\n")
        f.write("\\maketitle\n")
        f.write("\\begin{enumerate}\n\n")

        for idx, res in enumerate(results):
            latex_content = res.get("enhanced_latex") or res.get("raw_latex") or "% L·ªói: Kh√¥ng c√≥ LaTeX"
            f.write(f"\\item % C√¢u h·ªèi {idx+1} t·ª´ file: {res.get('original_filename', 'N/A')}\n")
            f.write(latex_content + "\n\n")

        f.write("\\end{enumerate}\n")
        f.write("\\end{document}\n")
    print(f"üìÑ Document LaTeX t·ªïng h·ª£p ƒë√£ l∆∞u t·∫°i: {compiled_tex_path}")

    # --- 2. Excel/CSV Export ---
    csv_path = os.path.join(output_dir, "processing_summary.csv")
    fieldnames = [
        "Original Filename", "Output Pattern", "OCR Engine", "OCR Confidence",
        "Raw LaTeX", "Enhanced LaTeX", "AI Status",
        "Syntax Valid", "Validation Message", "Processing Time (s)", "Error"
    ]
    with open(csv_path, "w", newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for res in results:
            writer.writerow({
                "Original Filename": res.get("original_filename"),
                "Output Pattern": res.get("output_filename_pattern"),
                "OCR Engine": res.get("ocr_engine_used"),
                "OCR Confidence": f"{res.get('ocr_confidence', 0.0):.2f}",
                "Raw LaTeX": res.get("raw_latex"),
                "Enhanced LaTeX": res.get("enhanced_latex"),
                "AI Status": res.get("ai_enhancement_status"),
                "Syntax Valid": res.get("latex_syntax_valid"),
                "Validation Message": res.get("validation_message"),
                "Processing Time (s)": f"{res.get('processing_time', 0.0):.2f}",
                "Error": res.get("error")
            })
    print(f"üìä B√°o c√°o CSV ƒë√£ l∆∞u t·∫°i: {csv_path}")

    # --- 3. JSON Export ---
    json_path = os.path.join(output_dir, "processing_summary.json")
    with open(json_path, "w", encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"üîó D·ªØ li·ªáu JSON ƒë√£ l∆∞u t·∫°i: {json_path}")

    # --- 4. Summary Report (Console) ---
    total_questions = len(results)
    successful_ocr = sum(1 for r in results if r.get("raw_latex"))
    successful_enhancement = sum(1 for r in results if r.get("enhanced_latex") and "Success" in str(r.get("ai_enhancement_status","")))
    syntax_ok = sum(1 for r in results if r.get("latex_syntax_valid"))
    total_processing_time = sum(r.get("processing_time", 0.0) for r in results)
    avg_confidence = 0
    if successful_ocr > 0:
         avg_confidence = sum(r.get('ocr_confidence',0.0) for r in results if r.get("raw_latex")) / successful_ocr

    manual_review_count = total_questions - syntax_ok # ƒê∆°n gi·∫£n h√≥a: c·∫ßn review n·∫øu syntax kh√¥ng ok
                                                    # Ho·∫∑c confidence th·∫•p (v√≠ d·ª• < 0.7)
    low_confidence_threshold = 0.7
    manual_review_confidence = sum(1 for r in results if r.get("raw_latex") and (r.get('ocr_confidence', 0.0) < low_confidence_threshold or not r.get("latex_syntax_valid")))


    report_md = f"""
    üìä **PROCESSING SUMMARY**
    ‚îú‚îÄ Total Questions Processed: {total_questions}
    ‚îú‚îÄ Successfully OCR'd: {successful_ocr} ({successful_ocr/total_questions:.2%} if total_questions > 0 else 0)
    ‚îú‚îÄ AI Enhancement Applied: {successful_enhancement} (tr√™n {sum(1 for r in results if r.get("raw_latex") and ENABLE_AI_ENHANCEMENT and GEMINI_API_KEY)} c√¢u c√≥ OCR v√† AI b·∫≠t)
    ‚îú‚îÄ Average OCR Confidence (cho c√¢u th√†nh c√¥ng): {avg_confidence:.3f}
    ‚îú‚îÄ Total Processing Time: {total_processing_time:.2f}s
    ‚îî‚îÄ Manual Review Recommended (syntax error or low confidence < {low_confidence_threshold}): {manual_review_confidence} questions

    üìà **QUALITY METRICS**
    ‚îú‚îÄ Valid LaTeX Syntax (basic check): {syntax_ok} questions
    ‚îî‚îÄ Potentially Needing Corrections: {total_questions - syntax_ok} questions
    """
    print("\n--- B√ÅO C√ÅO T√ìM T·∫ÆT ---")
    # print(report_md) # D·∫°ng Markdown ƒë·∫πp h∆°n
    display(Markdown(report_md))

    # Hi·ªÉn th·ªã m·ªôt v√†i k·∫øt qu·∫£ ƒë·∫ßu ra
    print("\n--- V√ç D·ª§ K·∫æT QU·∫¢ ---")
    for i, res in enumerate(results[:min(5, len(results))]): # Hi·ªÉn th·ªã 5 k·∫øt qu·∫£ ƒë·∫ßu
        print(f"\nC√¢u h·ªèi: {res.get('original_filename', 'N/A')} ({res.get('output_filename_pattern')})")
        print(f"  OCR Engine: {res.get('ocr_engine_used', 'N/A')}, Confidence: {res.get('ocr_confidence', 0.0):.2f}")
        print(f"  Raw LaTeX: {res.get('raw_latex', 'N/A')[:100]}...") # C·∫Øt b·ªõt cho g·ªçn
        if ENABLE_AI_ENHANCEMENT:
            print(f"  Enhanced LaTeX: {res.get('enhanced_latex', 'N/A')[:100]}...")
            print(f"  AI Status: {res.get('ai_enhancement_status', 'N/A')}")
        print(f"  Syntax Valid: {res.get('latex_syntax_valid', False)} ({res.get('validation_message', '')})")
        if res.get('error'):
            print(f"  L·ªói: {res.get('error')}")

    # H∆∞·ªõng d·∫´n t·∫£i file
    print(f"\n\nüìÇ C√°c file k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c '{OUTPUT_DIR}'.")
    print("B·∫°n c√≥ th·ªÉ t·∫£i v·ªÅ d∆∞·ªõi d·∫°ng ZIP b·∫±ng c√°ch click chu·ªôt ph·∫£i v√†o th∆∞ m·ª•c trong panel 'Files' b√™n tr√°i v√† ch·ªçn 'Download'.")
    # Ho·∫∑c t·∫°o file zip ƒë·ªÉ t·∫£i
    # shutil.make_archive(BASE_DIR, 'zip', BASE_DIR)
    # print(f"\nüóúÔ∏è ƒê√£ t·∫°o file {BASE_DIR}.zip. B·∫°n c√≥ th·ªÉ t·∫£i v·ªÅ t·ª´ panel Files.")


if 'processing_results' in locals() and processing_results:
    generate_report(processing_results, OUTPUT_DIR)
else:
    print("Ch∆∞a c√≥ k·∫øt qu·∫£ x·ª≠ l√Ω. Vui l√≤ng ch·∫°y b∆∞·ªõc 8 (Nh·∫≠p li·ªáu v√† X·ª≠ L√Ω).")

```

**C√°ch s·ª≠ d·ª•ng Notebook n√†y:**

1.  **M·ªü tr√™n Google Colab:** File > Open notebook > GitHub > D√°n URL c·ªßa Gist (n·∫øu b·∫°n l∆∞u n√≥ th√†nh Gist) ho·∫∑c upload file .ipynb.
2.  **Thi·∫øt l·∫≠p API Key (Cell 2):**
    *   C√°ch t·ªët nh·∫•t: V√†o menu "Secrets" (bi·ªÉu t∆∞·ª£ng ch√¨a kh√≥a b√™n tr√°i Colab), t·∫°o m·ªôt secret m·ªõi t√™n l√† `GEMINI_API_KEY` v√† d√°n API key c·ªßa Google AI Studio v√†o ƒë√≥.
    *   Ho·∫∑c: Ch·∫°y cell 2 v√† nh·∫≠p API key khi ƒë∆∞·ª£c h·ªèi.
3.  **Ch·∫°y t·ª´ng cell theo th·ª© t·ª±:**
    *   **Cell 1:** C√†i ƒë·∫∑t th∆∞ vi·ªán (ch·ªâ c·∫ßn ch·∫°y l·∫ßn ƒë·∫ßu ho·∫∑c khi session Colab kh·ªüi ƒë·ªông l·∫°i).
    *   **Cell 2:** Import v√† c·∫•u h√¨nh API.
    *   **Cell 3-7:** ƒê·ªãnh nghƒ©a c√°c h√†m ti·ªán √≠ch.
    *   **Cell 8:**
        *   Upload ·∫£nh c·ªßa b·∫°n v√†o th∆∞ m·ª•c `math_ocr_processor_2025/input_images` b·∫±ng c√°ch s·ª≠ d·ª•ng tr√¨nh qu·∫£n l√Ω file b√™n tr√°i c·ªßa Colab (k√©o th·∫£ ho·∫∑c click chu·ªôt ph·∫£i v√†o th∆∞ m·ª•c > Upload).
        *   Sau khi upload xong, ch·∫°y cell 8 ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh x·ª≠ l√Ω. N·∫øu th∆∞ m·ª•c `input_images` r·ªóng, n√≥ s·∫Ω t·∫°o v√†i ·∫£nh m·∫´u.
    *   **Cell 9:** Xem b√°o c√°o, xu·∫•t file v√† hi·ªÉn th·ªã v√≠ d·ª• k·∫øt qu·∫£.

**C√°c c·∫£i ti·∫øn v√† l∆∞u √Ω th√™m:**

*   **Render LaTeX Preview:** ƒê·ªÉ t·∫°o ·∫£nh preview PNG/SVG t·ª´ LaTeX tr√™n Colab, b·∫°n c·∫ßn c√†i ƒë·∫∑t m·ªôt b·∫£n ph√¢n ph·ªëi LaTeX ƒë·∫ßy ƒë·ªß (v√≠ d·ª•: TeX Live) v√† c√°c c√¥ng c·ª• nh∆∞ `pdflatex`, `dvisvgm`. ƒêi·ªÅu n√†y c√≥ th·ªÉ kh√° n·∫∑ng v√† m·∫•t th·ªùi gian c√†i ƒë·∫∑t. B·∫°n c√≥ th·ªÉ th√™m m·ªôt b∆∞·ªõc d√πng `matplotlib.mathtext` ƒë·ªÉ render c√¥ng th·ª©c ƒë∆°n gi·∫£n, nh∆∞ng n√≥ kh√¥ng ph·∫£i l√† m·ªôt tr√¨nh bi√™n d·ªãch LaTeX ƒë·∫ßy ƒë·ªß.
    ```python
    # V√≠ d·ª• render LaTeX d√πng Matplotlib (cho c√¥ng th·ª©c ƒë∆°n gi·∫£n)
    # import matplotlib.pyplot as plt
    # def render_latex_to_image(latex_str, output_path):
    #     try:
    #         fig, ax = plt.subplots(figsize=(max(1, len(latex_str)/10), 2)) # ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc
    #         ax.text(0, 0.5, f"${latex_str}$", size=15, va='center')
    #         ax.axis('off')
    #         plt.savefig(output_path, bbox_inches='tight', dpi=200)
    #         plt.close(fig)
    #         return output_path
    #     except Exception as e:
    #         print(f"L·ªói render LaTeX: {e}")
    #         return None
    ```
*   **Smart Question Detection & LaTeX Templating:** ƒê√¢y l√† m·ªôt t√°c v·ª• NLP ph·ª©c t·∫°p. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c m√¥ h√¨nh ph√¢n lo·∫°i vƒÉn b·∫£n ho·∫∑c LLM ƒë·ªÉ th·ª≠ ph√°t hi·ªán lo·∫°i c√¢u h·ªèi, sau ƒë√≥ √°p d·ª•ng template.
*   **Advanced Error Recovery:** C√≥ th·ªÉ bao g·ªìm vi·ªác th·ª≠ l·∫°i v·ªõi c√°c tham s·ªë ti·ªÅn x·ª≠ l√Ω kh√°c nhau ho·∫∑c crop l·∫°i v√πng ·∫£nh n·∫øu confidence th·∫•p.
*   **Collaborative Features (Overleaf):** Vi·ªác xu·∫•t ra file `.tex` t·ªïng h·ª£p ƒë√£ l√† b∆∞·ªõc ƒë·∫ßu. T√≠ch h·ª£p API Overleaf (n·∫øu c√≥) s·∫Ω ph·ª©c t·∫°p h∆°n.
*   **T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t:**
    *   **Model Quantization:** M·ªôt s·ªë model (nh∆∞ c·ªßa Hugging Face Transformers) c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞·ª£ng t·ª≠ h√≥a ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc v√† tƒÉng t·ªëc ƒë·ªô tr√™n CPU, c√≥ th·ªÉ ƒë√°nh ƒë·ªïi m·ªôt ch√∫t ƒë·ªô ch√≠nh x√°c.
    *   **Intelligent Caching:** L∆∞u k·∫øt qu·∫£ c·ªßa c√°c b∆∞·ªõc t·ªën th·ªùi gian (v√≠ d·ª•, k·∫øt qu·∫£ OCR cho m·ªôt ·∫£nh kh√¥ng ƒë·ªïi) ƒë·ªÉ kh√¥ng ph·∫£i x·ª≠ l√Ω l·∫°i.
*   **ƒê·ªô ch√≠nh x√°c c·ªßa "Confidence Score":** C√°c th∆∞ vi·ªán OCR kh√¥ng ph·∫£i l√∫c n√†o c≈©ng cung c·∫•p confidence score ƒë√°ng tin c·∫≠y ho·∫∑c d·ªÖ truy c·∫≠p. C√°c gi√° tr·ªã confidence t√¥i d√πng ·ªü tr√™n ph·∫ßn l·ªõn l√† ∆∞·ªõc l∆∞·ª£ng.
*   **H·∫°n ch·∫ø t√†i nguy√™n Colab:** C√°c session Colab c√≥ gi·ªõi h·∫°n v·ªÅ th·ªùi gian ch·∫°y, RAM v√† GPU (n·∫øu d√πng). C√°c t√°c v·ª• n·∫∑ng c√≥ th·ªÉ b·ªã ng·∫Øt.

B·ªô khung m√£ n√†y cung c·∫•p m·ªôt n·ªÅn t·∫£ng v·ªØng ch·∫Øc. B·∫°n c√≥ th·ªÉ m·ªü r·ªông v√† tinh ch·ªânh t·ª´ng ph·∫ßn d·ª±a tr√™n y√™u c·∫ßu c·ª• th·ªÉ v√† c√°c c√¥ng c·ª•/API m·ªõi xu·∫•t hi·ªán. Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi d·ª± √°n!
